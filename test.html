<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title></title>
</head>
<body>
<audio id="myaudio" controls autoplay></audio>
<input value="录音" type="button" id="record" />
<input value="播放" type="button" id="play" />
<script>

navigator.getUserMedia || (navigator.getUserMedia = navigator.mozGetUserMedia ||  navigator.webkitGetUserMedia || navigator.msGetUserMedia);

var myaudio = document.getElementById('stream');

if (navigator.getUserMedia) {
    //do something
    navigator.getUserMedia(
      {audio:true},
      function(stream){
        console.log("succeed!");
        console.log(stream);
        //创建一个音频环境对像
        audioContext = window.AudioContext || window.webkitAudioContext;
        context = new audioContext();

        //将声音输入这个对像
        audioInput = context.createMediaStreamSources(stream);
        
        //设置音量节点
        volume = context.createGain();
        audioInput.connect(volume);

        //创建缓存，用来缓存声音
        var bufferSize = 2048;

        // 创建声音的缓存节点，createJavaScriptNode方法的
        // 第二个和第三个参数指的是输入和输出都是双声道。
        recorder = context.createJavaScriptNode(bufferSize, 2, 2);

        // 录音过程的回调函数，基本上是将左右两声道的声音
        // 分别放入缓存。
        recorder.onaudioprocess = function(e){
            console.log('recording');
            var left = e.inputBuffer.getChannelData(0);
            var right = e.inputBuffer.getChannelData(1);
            // we clone the samples
            leftchannel.push(new Float32Array(left));
            rightchannel.push(new Float32Array(right));
            recordingLength += bufferSize;
        }

        // 将音量节点连上缓存节点，换言之，音量节点是输入
        // 和输出的中间环节。
        volume.connect(recorder);

        // 将缓存节点连上输出的目的地，可以是扩音器，也可以
        // 是音频文件。
        recorder.connect(context.destination); 
        
      },
      function(e){
        console.log("fail!");
        console.log("e");


      }
    );
} else {
    console.log('your browser not support getUserMedia');
}


/*
var AudioContext=AudioContext||webkitAudioContext;
var context=new AudioContext;
//调整兼容
navigator.getUserMedia=
  navigator.getUserMedia||
  navigator.webkitGetUserMedia||
  navigator.mozGetUserMedia;
//请求麦克风
navigator.getUserMedia({audio:true},function(e){
  var data,p;
  //从麦克风的输入流创建源节点
  var stream=context.createMediaStreamSource(e);
  //用于录音的processor节点
  var recorder=context.createScriptProcessor(1024,1,0);
  recorder.onaudioprocess=function(e){
    if(record.value=="停止")data.push(e.inputBuffer.getChannelData(0));
  };
  //用于播放的processor节点
  var player=context.createScriptProcessor(1024,0,1);
  player.onaudioprocess=function(e){
    if(!data)return;
    var i,s=data[p++];
    if(!s)return play.value=="停止"&&play.click();
    var buffer=e.outputBuffer.getChannelData(0);
    for(i=0;i<s.length;i++)buffer[i]=s[i];
  };
  //录音/停止 按钮点击动作
  record.onclick=function(){
    if(record.value=="录音")
      return data=[],stream.connect(recorder),this.value="停止";
    if(record.value=="停止")
      return stream.disconnect(),this.value="录音";
  };
  //播放/停止 按钮点击动作
  play.onclick=function(){
    if(this.value=="播放")
      return p=0,player.connect(context.destination),this.value="停止";
    if(this.value=="停止")
      return player.disconnect(),this.value="播放";
  };
},function(e){
  console.log("请求麦克风失败");
});
*/
</script>
</body>
</html>